{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkfLXeKs4QFq"
      },
      "source": [
        "\n",
        "# RoBERTa を 動かす\n",
        "https://huggingface.co/rinna/japanese-roberta-base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPjMPwYmRusV"
      },
      "source": [
        "- ライブラリ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44G0UEQj4CRF"
      },
      "source": [
        "# Huggingface Transformersのインストール\n",
        "!pip install transformers\n",
        "\n",
        "# Sentencepieceのインストール\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMy7-7u4RsR_"
      },
      "source": [
        "- モデル読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MmlMsHE4hHX"
      },
      "source": [
        "from transformers import T5Tokenizer, RobertaForMaskedLM\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n",
        "tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading\n",
        "\n",
        "model = RobertaForMaskedLM.from_pretrained(\"rinna/japanese-roberta-base\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEpT2N_JRm8r"
      },
      "source": [
        "- 元のテキスト入れる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNba6UeVBQYE"
      },
      "source": [
        "# original text\n",
        "text_orig = \"ヤマザキパンの祭りは[MASK]に開かれる。\"\n",
        "# text_orig = \"くお～！！ぶつかる～！！ここでアクセル全開、[MASK]を右に！\"\n",
        "# text = \"4年に1度オリンピックは開かれる。\"\n",
        "\n",
        "# prepend [CLS]\n",
        "text = \"[CLS]\" + text_orig\n",
        "\n",
        "# tokenize\n",
        "tokens = tokenizer.tokenize(text)\n",
        "print(tokens)\n",
        "\n",
        "print('mask index :' , tokens.index('[MASK]'))\n",
        "# tokens.index('オリンピック')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPMk8jO_Rczf"
      },
      "source": [
        "- mask index入れる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um2lnCrfCFR0"
      },
      "source": [
        "# mask a token\n",
        "masked_idx = 9 # ここにMASKのindexを入れる"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqqAFiRRRV2N"
      },
      "source": [
        "tokens[masked_idx] = tokenizer.mask_token\n",
        "# print(tokens)  # output: ['[CLS]', '▁4', '年に', '1', '度', '[MASK]', 'は', '開かれる', '。']\n",
        "\n",
        "# convert to ids\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "# print(token_ids)  # output: [4, 1602, 44, 24, 368, 6, 11, 21583, 8]\n",
        "\n",
        "# convert to tensor\n",
        "token_tensor = torch.tensor([token_ids])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPU に転送するか判定"
      ],
      "metadata": {
        "id": "34yX675vTKav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "I4etpQCHTORc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.eval()\n",
        "model = model.to(device)\n",
        "token_tensor = token_tensor.to(device)"
      ],
      "metadata": {
        "id": "zugnAi2_U2n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okam5GAURhL_"
      },
      "source": [
        "- 推論する"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get the top 10 predictions of the masked token\n",
        "with torch.no_grad():\n",
        "    outputs = model(token_tensor)\n",
        "    predictions = outputs[0][0, masked_idx].topk(10)\n",
        "\n",
        "print(text_orig)\n",
        "\n",
        "for i, index_t in enumerate(predictions.indices):\n",
        "    index = index_t.item()\n",
        "    token = tokenizer.convert_ids_to_tokens([index])[0]\n",
        "    print(i, token)"
      ],
      "metadata": {
        "id": "IyQaknpnVPzR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}